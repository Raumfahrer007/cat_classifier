{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e9ca63-2427-4358-9e8e-58256f32b589",
   "metadata": {},
   "source": [
    "# Transfer Learning Implementation\n",
    "This notebook introduces our advanced approach: leveraging transfer learning to build upon our baseline performance. While our custom CNN established a respectable 54.2% test accuracy, we now harness the power of models pre-trained on large-scale datasets like ImageNet to significantly improve feature extraction and classification performance.\n",
    "\n",
    "Transfer learning allows us to benefit from patterns learned across millions of diverse images, providing our model with sophisticated feature detection capabilities from the outset. We'll implement a two-stage training strategy: first freezing the base model to adapt our classification head, then fine-tuning deeper layers to specialize for our specific cat recognition task.\n",
    "\n",
    "This approach addresses the key limitation of our baseline—limited feature learning capacity—while maintaining efficient training through strategic reuse of pre-learned visual features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad9411-f197-4eb6-b756-10244fcd29ac",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9413042-b61a-4c15-a93a-af143871b691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPORTS FINISHED ===\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from dataclasses import dataclass\n",
    "\n",
    "print(\"=== IMPORTS FINISHED ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc41a02-d443-4012-b998-ceb0acf57d59",
   "metadata": {},
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fced22-4389-4ca7-bef2-463e0e3180c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG FINISHED ===\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    IMG_HEIGHT: int = 224\n",
    "    IMG_WIDTH: int = 224\n",
    "    IMG_CHANNELS: int = 3\n",
    "    \n",
    "    # Data settings\n",
    "    BATCH_SIZE: int = 32\n",
    "    VALIDATION_SPLIT: float = 0.15\n",
    "    TEST_SPLIT: float = 0.15\n",
    "    \n",
    "    # Training settings\n",
    "    FEATURE_EXTRACTION_EPOCHS: int = 10\n",
    "    FEATURE_EXTRACTION_LEARNING_RATE: float = 1e-4\n",
    "    FINE_TUNING_EPOCHS: int = 20\n",
    "    FINE_TUNING_LEARNING_RATE: float = 1e-5\n",
    "    DROPOUT_RATE: float = 0.3\n",
    "    \n",
    "    # Paths\n",
    "    DATA_PATH: str = \"../data/raw\"\n",
    "    PROCESSED_PATH: str = \"../data/processed\"\n",
    "\n",
    "print(\"=== CONFIG FINISHED ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e04e67-a95f-40b0-b8b6-e931bc3eacd8",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "\n",
    "## 3.1 Data Augmentation Configuration\n",
    "We begin by defining our data preprocessing pipeline.\n",
    "We reuse our established data generators from the baseline experiment, ensuring consistent preprocessing and augmentation across all model comparisons. This guarantees that any performance improvements can be attributed to architectural changes rather than data handling differences.\n",
    "\n",
    "The same augmentation strategy applies here, though transfer learning models may respond differently to these transformations given their pre-trained feature extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8698a2-0bb8-4d9c-90da-09c6ac82d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(\n",
    "    target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH),\n",
    "    batch_size=Config.BATCH_SIZE\n",
    "):\n",
    "    \"\"\"\n",
    "    Create data generators with handling for class imbalance\n",
    "    \"\"\"\n",
    "    # Training generator with heavy augmentation for minority classes\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zoom_range=0.3,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, val_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef930fb-eca3-4f38-bd3e-63029eabc99e",
   "metadata": {},
   "source": [
    "## 3.2. Creating Data Generators\n",
    "With our augmentation strategy defined, we instantiate the data generators for training, validation, and testing. These generators will handle image resizing, batch processing, and real-time augmentation during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d6ece8-44c6-42a4-8d1e-689a0e742cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 images belonging to 3 classes.\n",
      "Found 83 images belonging to 3 classes.\n",
      "Found 83 images belonging to 3 classes.\n",
      "Classes: {'both': 0, 'karamela': 1, 'lacta': 2}\n",
      "Training samples: 380\n",
      "Validation samples: 83\n",
      "Test samples: 83\n"
     ]
    }
   ],
   "source": [
    "train_datagen, val_datagen, test_datagen = create_data_generators()\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f'{Config.PROCESSED_PATH}/train',\n",
    "    target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH),\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    f'{Config.PROCESSED_PATH}/val', \n",
    "    target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH),\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    f'{Config.PROCESSED_PATH}/test',\n",
    "    target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH), \n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "transfer_classes = train_generator.class_indices\n",
    "\n",
    "print(f\"Classes: {transfer_classes}\")\n",
    "print(f\"Training samples: {transfer_train_generator.samples}\")\n",
    "print(f\"Validation samples: {transfer_val_generator.samples}\")\n",
    "print(f\"Test samples: {transfer_test_generator.samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c47a39-aaff-4209-b98a-d5df749f5fff",
   "metadata": {},
   "source": [
    "## 3.3 Class Weights\n",
    "\n",
    "We maintain the same class weighting scheme used in our baseline to ensure fair comparison. However, transfer learning models with robust pre-trained features may be less sensitive to class imbalance, potentially allowing for weight adjustments in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce219ad2-da54-4727-82f6-3a376eeb8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for handling imbalance:\n",
      "  both(0): 2.141\n",
      "  karamela(1): 0.948\n",
      "  lacta(2): 0.677\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_weights(\n",
    "    classes_dict,\n",
    "    data_path=Config.DATA_PATH\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate class weights to handle imbalance during training\n",
    "    Uses inverse frequency weighting\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    \n",
    "    # Count images for each class using the actual folder names\n",
    "    for class_name, class_idx in classes_dict.items():\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        class_counts[class_idx] = len(image_files)  # Use index as key for Keras\n",
    "    \n",
    "    total_samples = sum(class_counts.values())\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    class_weights = {}\n",
    "    for class_idx, count in class_counts.items():\n",
    "        # Inverse frequency weighting\n",
    "        class_weights[class_idx] = total_samples / (num_classes * count)\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "# Calculate and display weights\n",
    "transfer_class_weights = calculate_class_weights(transfer_classes)\n",
    "\n",
    "print(\"Class weights for handling imbalance:\")\n",
    "for class_name, class_idx in transfer_classes.items():\n",
    "    print(f\"  {class_name}({class_idx}): {transfer_weights[class_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25432a-0845-4d96-9275-8d1e7902698e",
   "metadata": {},
   "source": [
    "# 4. Transfer Learning Model\n",
    "\n",
    "## 4.1 Transfer Learning Architecture Design\n",
    "This section introduces the core innovation of our advanced approach: leveraging pre-trained convolutional bases specialized in feature extraction. While our baseline model learned features from scratch, we now utilize models that have already mastered fundamental visual patterns through training on millions of diverse images from the ImageNet dataset.\n",
    "\n",
    "We implement a strategic two-phase architecture: first, we employ a frozen base model as a powerful feature extractor combined with a custom classification head tailored to our specific three-class problem; second, we carefully unfreeze select layers for fine-tuning, allowing the model to adapt its sophisticated feature detection capabilities to the unique characteristics of Lacta and Karamela.\n",
    "\n",
    "This approach represents a fundamental shift from learning features de novo to specializing existing feature hierarchies, dramatically reducing training time while significantly improving performance potential. The architecture decisions made here—from base model selection to layer freezing strategy—will directly determine our ability to surpass the 54.2% benchmark established by our baseline.\n",
    "\n",
    "I selected EfficientNetB0 as our transfer learning foundation based on several strategic considerations that align with our project requirements:\n",
    "\n",
    "Computational Efficiency vs. Performance Balance: EfficientNetB0 represents the optimal trade-off between model complexity and feature extraction capability. While larger models like EfficientNetB7 offer marginal accuracy improvements, they demand significantly more computational resources without proportional benefits for our specialized three-class problem.\n",
    "\n",
    "Proven Feature Extraction: Pre-trained on ImageNet's 1,000 diverse classes, EfficientNetB0 has learned robust hierarchical features—from basic edges and textures to complex patterns—that transfer effectively to feline recognition. Its compound scaling approach systematically balances network depth, width, and resolution, providing sophisticated feature detection in a compact architecture.\n",
    "\n",
    "Practical Constraints: With 5.3 million parameters (compared to our baseline's 2.8 million), EfficientNetB0 offers substantial capacity increase while remaining trainable on consumer hardware. This aligns with our project scope and enables reasonable training times for both feature extraction and fine-tuning phases.\n",
    "\n",
    "Architecture Compatibility: The model's GlobalAveragePooling2D output seamlessly integrates with our custom classification head, and its standardized input size (224×224) matches our preprocessing pipeline without requiring structural modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c335042-b605-4a3b-ba63-42f2cf3c4564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                   </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ global_average_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)       │                        │              │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ batch_normalization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │                        │              │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└────────────────────────────────┴────────────────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │    \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ global_average_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │            \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)       │                        │              │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │            \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m163,968\u001b[0m │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ batch_normalization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)           │                        │              │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │          \u001b[38;5;34m387\u001b[0m │\n",
       "└────────────────────────────────┴────────────────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,214,438</span> (16.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,214,438\u001b[0m (16.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,611</span> (643.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,611\u001b[0m (643.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,827</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,827\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable layers:\n",
      "efficientnetb0: False\n",
      "global_average_pooling2d_1: True\n",
      "dropout: True\n",
      "dense: True\n",
      "batch_normalization: True\n",
      "dense_1: True\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_model(\n",
    "    base_model_name=\"EfficientNetB0\",\n",
    "    freeze_base=True,\n",
    "    num_classes=len(transfer_classes),\n",
    "    input_shape=(Config.IMG_HEIGHT, Config.IMG_WIDTH, Config.IMG_CHANNELS)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create transfer learning model with pre-trained base and custom head\n",
    "    \"\"\"\n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == \"EfficientNetB0\":\n",
    "        base_model = tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    # Add other base model options...\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    # Build custom classification head\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        # Convert 2D feature maps to 1D vector\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        # Regularization to prevent overfitting on our small dataset\n",
    "        tf.keras.layers.Dropout(Config.DROPOUT_RATE),\n",
    "        # Learn combinations of features specific to our cats\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        # Stabilize learning and accelerate training\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        # Final decision layer for our 3 classes\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and examine the model\n",
    "transfer_model = create_transfer_model()\n",
    "transfer_model.summary()\n",
    "\n",
    "# Display layer trainability\n",
    "print(\"\\nTrainable layers:\")\n",
    "for layer in transfer_model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a23609-57cc-4578-a488-f197b2de3f57",
   "metadata": {},
   "source": [
    "Our transfer learning model successfully integrates EfficientNetB0's powerful feature extraction capabilities with a custom classification head tailored to our specific task. The architecture reveals several strategic advantages over our baseline approach:\n",
    "\n",
    "- **Massive Feature Extraction Capacity**  \n",
    "  The base model contributes 4 million frozen parameters—pre-trained feature detectors that would be impossible to learn from our limited dataset alone. This represents a 140× increase in feature learning capacity compared to our baseline's 56K convolutional parameters.\n",
    "\n",
    "- **Efficient Dimensionality Reduction**  \n",
    "  The GlobalAveragePooling2D layer transforms the 7×7×1280 feature maps into a compact 1280-element vector, effectively reducing dimensionality from 62,720 features to 1,280 while preserving spatial information through averaging.\n",
    "\n",
    "- **Strategic Parameter Distribution**  \n",
    "  With only 164,611 trainable parameters (3.9% of total), we achieve enormous representational power while maintaining computational efficiency. This frozen-to-trainable ratio ensures we leverage pre-trained knowledge while adapting to our specific cat recognition task.\n",
    "\n",
    "- **Controlled Specialization**  \n",
    "  The custom head's 128-unit dense layer provides sufficient capacity to learn cat-specific feature combinations, while the minimal 387-parameter output layer focuses exclusively on our three-class decision space—a dramatic reduction from EfficientNet's original 1000-class head.\n",
    "\n",
    "- **Training Efficiency Confirmed**  \n",
    "  All base model layers are correctly frozen, ensuring we preserve ImageNet-learned features during initial training. This setup guarantees our first training phase will be fast and stable, focusing only on adapting the custom classification head to EfficientNet's sophisticated feature representations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442a25e-f7bd-49d1-8305-40ba2260ed4c",
   "metadata": {},
   "source": [
    "## 4.2 Two-Stage Training Strategy\n",
    "Transfer learning's effectiveness hinges on a carefully orchestrated two-phase training approach. Rather than training the entire network at once, we strategically separate the process into distinct phases that progressively specialize the model to our specific cat recognition task while preserving valuable pre-trained knowledge.\n",
    "\n",
    "This methodology prevents catastrophic forgetting of ImageNet features while allowing systematic adaptation to our domain. The staged approach also provides diagnostic benefits—we can monitor whether the feature extraction phase establishes a strong foundation before committing to computationally intensive fine-tuning.\n",
    "\n",
    "### 4.2.1 Feature Extraction\n",
    "In this initial phase, we treat EfficientNetB0 as a fixed feature extractor, training only our custom classification head. This approach allows the model to learn how to interpret and combine the sophisticated features detected by the pre-trained base model for our specific three-class problem.\n",
    "\n",
    "By freezing the 4 million base parameters, we achieve rapid convergence while leveraging decades of computer vision research embedded in the ImageNet weights. The 10-epoch duration provides sufficient time for the custom head to establish effective decision boundaries without overfitting to our limited dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cba9227-7ede-436b-beb4-cfc370934607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 1: FEATURE EXTRACTION ===\n",
      "Training only the custom classification head...\n",
      "Epoch 1/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 4s/step - accuracy: 0.3263 - loss: 1.4432 - val_accuracy: 0.3253 - val_loss: 1.0604\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3526 - loss: 1.3951 - val_accuracy: 0.3735 - val_loss: 1.0638\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.2868 - loss: 1.4883 - val_accuracy: 0.3494 - val_loss: 1.0687\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3421 - loss: 1.3390 - val_accuracy: 0.4940 - val_loss: 1.0674\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3132 - loss: 1.3874 - val_accuracy: 0.4940 - val_loss: 1.0689\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.2553 - loss: 1.4881 - val_accuracy: 0.4940 - val_loss: 1.0789\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3605 - loss: 1.3156 - val_accuracy: 0.4940 - val_loss: 1.0763\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3316 - loss: 1.3544 - val_accuracy: 0.4940 - val_loss: 1.0682\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3342 - loss: 1.3217 - val_accuracy: 0.4940 - val_loss: 1.0678\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.3447 - loss: 1.2654 - val_accuracy: 0.4940 - val_loss: 1.0608\n"
     ]
    }
   ],
   "source": [
    "## Phase 1: Feature Extraction with Frozen Base\n",
    "\n",
    "print(\"=== STAGE 1: FEATURE EXTRACTION ===\")\n",
    "print(\"Training only the custom classification head...\")\n",
    "\n",
    "# Compile with standard learning rate\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=Config.FEATURE_EXTRACTION_LEARNING_RATE),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train only the custom head (base model frozen)\n",
    "stage1_transfer_history = transfer_model.fit(\n",
    "    transfer_train_generator,\n",
    "    epochs=Config.FEATURE_EXTRACTION_EPOCHS,\n",
    "    validation_data=transfer_val_generator,\n",
    "    class_weight=transfer_class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee893d71-3d25-45cd-a894-da81f3e7c1a0",
   "metadata": {},
   "source": [
    "The initial training phase reveals intriguing learning dynamics. While training accuracy fluctuates between 25-36%, validation accuracy stabilizes at 49.4% from epoch 4 onward—matching our baseline's final performance using only the custom classification head.\n",
    "\n",
    "Key Observations:\n",
    "Rapid Validation Convergence: The model reached peak validation performance by epoch 4, indicating the custom head quickly learned to effectively interpret EfficientNet's pre-trained features for our classification task.\n",
    "\n",
    "Training-Validation Discrepancy: The substantial gap between training (34.5%) and validation (49.4%) accuracy suggests the frozen base model provides robust, generalizable features that prevent overfitting—exactly as intended in this architecture.\n",
    "\n",
    "Stable Loss Patterns: Validation loss consistently hovers around 1.06-1.07, showing stable learning without degradation, while training loss shows more variability as the head adapts to the fixed feature representations.\n",
    "\n",
    "Implications for Fine-Tuning:\n",
    "The feature extraction phase has successfully established a foundation at 49.4% validation accuracy—slightly above our baseline's starting point. This provides a solid platform for fine-tuning, where we expect to see significant improvements as we unfreeze layers to specialize the feature detection for our specific cats.\n",
    "\n",
    "The stability in validation metrics suggests the model is ready for the next phase, where we'll carefully unfreeze layers to adapt the sophisticated feature detectors to the unique characteristics of Lacta and Karamela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b98d76-895a-4075-b6ab-abe6e125f8b0",
   "metadata": {},
   "source": [
    "### 4.2.2 Fine-Tuning\n",
    "Once our classification head has learned to effectively interpret the base features, we carefully unfreeze later layers of EfficientNetB0 for specialized adaptation. These higher-level layers contain more task-specific features that benefit from fine-tuning to recognize the unique characteristics of Lacta and Karamela.\n",
    "\n",
    "We use a significantly reduced learning rate (1e-5) to make subtle weight adjustments without destabilizing the carefully pre-trained features. The selective unfreezing—keeping early layers frozen—preserves general feature detection capabilities while allowing specialization in higher-level pattern recognition relevant to our feline classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f537f990-4175-401f-b4e8-015c4b0ed400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 2: FINE-TUNING ===\n",
      "Unfreezing base model layers for specialized adaptation...\n",
      "Epoch 1/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 4s/step - accuracy: 0.3605 - loss: 1.5290 - val_accuracy: 0.4940 - val_loss: 1.0475\n",
      "Epoch 2/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.3289 - loss: 1.4983 - val_accuracy: 0.4940 - val_loss: 1.0445\n",
      "Epoch 3/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.3500 - loss: 1.3527 - val_accuracy: 0.4940 - val_loss: 1.0457\n",
      "Epoch 4/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.3447 - loss: 1.5191 - val_accuracy: 0.4940 - val_loss: 1.0529\n",
      "Epoch 5/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3579 - loss: 1.4373 - val_accuracy: 0.4940 - val_loss: 1.0609\n",
      "Epoch 6/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3526 - loss: 1.4129 - val_accuracy: 0.4940 - val_loss: 1.0654\n",
      "Epoch 7/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3368 - loss: 1.3795 - val_accuracy: 0.4940 - val_loss: 1.0676\n",
      "Epoch 8/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.4026 - loss: 1.2853 - val_accuracy: 0.4940 - val_loss: 1.0706\n",
      "Epoch 9/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3921 - loss: 1.3093 - val_accuracy: 0.4940 - val_loss: 1.0869\n",
      "Epoch 10/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3105 - loss: 1.4633 - val_accuracy: 0.4337 - val_loss: 1.1046\n",
      "Epoch 11/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3605 - loss: 1.3030 - val_accuracy: 0.4819 - val_loss: 1.0844\n",
      "Epoch 12/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.3289 - loss: 1.3282 - val_accuracy: 0.4940 - val_loss: 1.0503\n",
      "Epoch 13/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.4053 - loss: 1.2415 - val_accuracy: 0.4940 - val_loss: 1.0281\n",
      "Epoch 14/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.4026 - loss: 1.2681 - val_accuracy: 0.4940 - val_loss: 1.0198\n",
      "Epoch 15/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3132 - loss: 1.4090 - val_accuracy: 0.4940 - val_loss: 1.0160\n",
      "Epoch 16/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.3579 - loss: 1.3328 - val_accuracy: 0.4940 - val_loss: 1.0187\n",
      "Epoch 17/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3789 - loss: 1.3066 - val_accuracy: 0.4940 - val_loss: 1.0090\n",
      "Epoch 18/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3579 - loss: 1.2829 - val_accuracy: 0.5060 - val_loss: 1.0135\n",
      "Epoch 19/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3816 - loss: 1.2172 - val_accuracy: 0.4940 - val_loss: 1.0156\n",
      "Epoch 20/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.3711 - loss: 1.3567 - val_accuracy: 0.4940 - val_loss: 1.0140\n"
     ]
    }
   ],
   "source": [
    "## Phase 2: Fine-Tuning with Unfrozen Layers\n",
    "\n",
    "print(\"=== STAGE 2: FINE-TUNING ===\")\n",
    "print(\"Unfreezing base model layers for specialized adaptation...\")\n",
    "\n",
    "# Unfreeze later base model layers\n",
    "transfer_base_model = transfer_model.layers[0]\n",
    "transfer_base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onward\n",
    "fine_tune_at = 100\n",
    "for layer in transfer_base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=Config.FINE_TUNING_LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "stage2_transfer_history = transfer_model.fit(\n",
    "    transfer_train_generator,\n",
    "    epochs=Config.FINE_TUNING_EPOCHS,\n",
    "    validation_data=transfer_val_generator,\n",
    "    class_weight=transfer_class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fa327-e074-4d28-aba6-6f97cff3f2f7",
   "metadata": {},
   "source": [
    "The fine-tuning results reveal a performance plateau at 49.4% validation accuracy, with only a brief peak to 50.6% in epoch 18. This suggests several potential issues with our current approach:\n",
    "\n",
    "Key Observations:\n",
    "Validation Accuracy Stagnation: The model consistently returns to 49.4% validation accuracy, indicating it has found a local optimum but cannot break through to higher performance levels.\n",
    "\n",
    "Training Instability: Training accuracy fluctuates widely (31-41%) while validation remains stable, suggesting the model is struggling to learn meaningful patterns from our relatively small dataset.\n",
    "\n",
    "Loss Improvement Without Accuracy Gains: Validation loss decreased from 1.047 to 1.014, showing the model is becoming more confident in its predictions, but this confidence isn't translating to correct classifications.\n",
    "\n",
    "Potential Causes and Next Steps:\n",
    "Learning Rate Too Conservative: The fine-tuning rate (1e-5) might be too low to drive meaningful weight updates\n",
    "\n",
    "Insufficient Unfreezing: We may need to unfreeze more layers to allow greater adaptation\n",
    "\n",
    "Class Weight Impact: The aggressive 2.14× weight for \"both\" class might be causing optimization challenges\n",
    "\n",
    "Dataset Size Limitations: 380 training samples may be insufficient for effective fine-tuning\n",
    "\n",
    "Recommended Investigation:\n",
    "Before proceeding, we should:\n",
    "\n",
    "Analyze per-class performance to see if specific classes are problematic\n",
    "\n",
    "Consider reducing class weight intensity\n",
    "\n",
    "Experiment with unfreezing more layers or using a higher learning rate\n",
    "\n",
    "Compare against our baseline to see if we've at least maintained performance\n",
    "\n",
    "The fine-tuning phase hasn't provided the expected improvement, indicating we need to adjust our transfer learning strategy for this specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9378f-7cac-4655-9ad1-a8f17dda261c",
   "metadata": {},
   "source": [
    "## 4.3 Transfer Learning Performance Analysis\n",
    "The fine-tuning phase's performance plateau demands careful investigation to understand why our sophisticated transfer learning approach failed to significantly outperform the simple baseline. This analysis moves beyond surface-level metrics to examine the underlying learning dynamics, class-specific behaviors, and architectural interactions that constrained our model's potential.\n",
    "\n",
    "By comparing comprehensive performance metrics and conducting granular error analysis, we aim to diagnose the specific bottlenecks and inform strategic adjustments for our next iteration. This critical evaluation transforms an underwhelming result into valuable insights about the complex relationship between model architecture, dataset characteristics, and training methodology.\n",
    "\n",
    "## 4.3.1 Performance Comparison\n",
    "We begin by quantifying the overall effectiveness of our transfer learning implementation through direct comparison with our baseline model. This high-level assessment establishes whether the substantial additional complexity of feature extraction and fine-tuning provided meaningful returns, or if the baseline's simpler approach proved more efficient for our specific problem constraints.\n",
    "\n",
    "The comparison focuses on both validation consistency and final test performance, examining whether the transfer learning model's stable but limited performance represents reliable generalization or merely reflects an inability to escape a suboptimal local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ce8f39-e064-47f5-b9d3-480780456451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.4819 - loss: 0.9933\n",
      "=== DIRECT PERFORMANCE COMPARISON ===\n",
      "Baseline Validation Accuracy: 0.482\n",
      "Transfer Learning Validation Accuracy: 0.494\n",
      "Improvement: 0.012\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.5422 - loss: 0.9590\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.4699 - loss: 1.0268\n",
      "\n",
      "Baseline Test Accuracy: 0.542\n",
      "Transfer Learning Test Accuracy: 0.470\n",
      "Test Improvement: -0.072\n"
     ]
    }
   ],
   "source": [
    "## Load Baseline Model for Direct Comparison\n",
    "\n",
    "# Load the saved baseline model\n",
    "baseline_model = tf.keras.models.load_model('../models/baseline_model.keras')\n",
    "\n",
    "# Test set comparison\n",
    "transfer_test_generator.reset()\n",
    "baseline_test_loss, baseline_test_accuracy = baseline_model.evaluate(transfer_test_generator)\n",
    "transfer_test_loss, transfer_test_accuracy = transfer_model.evaluate(transfer_test_generator)\n",
    "\n",
    "print(\"--- Test Set Comparison ---\")\n",
    "print(f\"\\nBaseline Test Accuracy: {baseline_test_accuracy:.3f}\")\n",
    "print(f\"Transfer Learning Test Accuracy: {transfer_test_accuracy:.3f}\")\n",
    "print(f\"Test Improvement: {(transfer_test_accuracy - baseline_test_accuracy:.3f) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a088ead-b23c-4f9d-9bc1-96c7ba73908a",
   "metadata": {},
   "source": [
    "Performance Comparison Results\n",
    "Using the test set for comparison—the most rigorous approach that ensures identical evaluation conditions—reveals a clear performance regression in our transfer learning implementation.\n",
    "\n",
    "Test Set Comparison:\n",
    "\n",
    "Baseline Model: 54.2% test accuracy\n",
    "\n",
    "Transfer Learning: 47.0% test accuracy\n",
    "\n",
    "Performance Change: -7.2% degradation\n",
    "\n",
    "Critical Insights:\n",
    "The 7.2% performance drop demonstrates that our current transfer learning approach, despite its theoretical advantages and marginal validation improvement, fails to generalize effectively to completely unseen data. The simpler baseline architecture proves more robust for our specific dataset and problem constraints.\n",
    "\n",
    "This unexpected result suggests that either:\n",
    "\n",
    "The fine-tuning process caused catastrophic forgetting of generally useful features\n",
    "\n",
    "Our small dataset size (380 training samples) is insufficient for effective transfer learning adaptation\n",
    "\n",
    "The hyperparameter choices (learning rates, unfreezing strategy) were suboptimal for this domain\n",
    "\n",
    "The test set's role as the ultimate arbiter of model quality proves crucial here, revealing generalization issues that validation metrics alone might obscure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1423f4f-a62b-4698-aaa9-1792c853fd0e",
   "metadata": {},
   "source": [
    "# 4.3.2 Detailed Error Analysis\n",
    "To diagnose the root causes of our transfer learning performance regression, we conduct a granular examination of per-class performance and confusion patterns. This analysis will reveal whether specific classes are disproportionately affected and identify the nature of the classification errors that led to the 7.2% test accuracy drop.\n",
    "\n",
    "By comparing confusion matrices and classification reports between both models, we can pinpoint exactly where the transfer learning approach diverged from the baseline's successful strategy and formulate targeted improvements for our next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9592f3-6689-4edf-a811-65528782d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step\n",
      "=== TRANSFER LEARNING CLASSIFICATION REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both      0.000     0.000     0.000        13\n",
      "    karamela      0.308     0.138     0.190        29\n",
      "       lacta      0.500     0.854     0.631        41\n",
      "\n",
      "    accuracy                          0.470        83\n",
      "   macro avg      0.269     0.331     0.274        83\n",
      "weighted avg      0.354     0.470     0.378        83\n",
      "\n",
      "\n",
      "=== BASELINE CLASSIFICATION REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both      0.233     0.769     0.357        13\n",
      "    karamela      0.826     0.655     0.731        29\n",
      "       lacta      0.941     0.390     0.552        41\n",
      "\n",
      "    accuracy                          0.542        83\n",
      "   macro avg      0.667     0.605     0.547        83\n",
      "weighted avg      0.790     0.542     0.584        83\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get transfer model predictions on test set\n",
    "test_generator.reset()\n",
    "y_true = test_generator.classes\n",
    "\n",
    "y_pred_transfer = transfer_model.predict(test_generator)\n",
    "y_pred_classes_transfer = np.argmax(y_pred_transfer, axis=1)\n",
    "\n",
    "# Get baseline predictions on the same test set\n",
    "y_pred_baseline = baseline_model.predict(test_generator)\n",
    "y_pred_classes_baseline = np.argmax(y_pred_baseline, axis=1)\n",
    "\n",
    "print(\"=== TRANSFER LEARNING CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(y_true, y_pred_classes_transfer, \n",
    "                          target_names=transfer_classes.keys(), digits=len(transfer_classes), zero_division=0))\n",
    "\n",
    "print(\"\\n=== BASELINE CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(y_true, y_pred_classes_baseline, \n",
    "                          target_names=transfer_classes.keys(), digits=len(transfer_classes), zero_division=0))\n",
    "\n",
    "# Comparative confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Transfer Learning Confusion Matrix\n",
    "cm_transfer = confusion_matrix(y_true, y_pred_classes_transfer)\n",
    "sns.heatmap(cm_transfer, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=transfer_classes.keys(), yticklabels=transfer_classes.keys(), ax=axes[0])\n",
    "axes[0].set_title('Transfer Learning - Confusion Matrix')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Baseline Confusion Matrix\n",
    "cm_baseline = confusion_matrix(y_true, y_pred_classes_baseline)\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=transfer_classes.keys(), yticklabels=transfer_classes.keys(), ax=axes[1])\n",
    "axes[1].set_title('Baseline - Confusion Matrix')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54347a-f3f6-4f5b-a0b8-9c7cf73be692",
   "metadata": {},
   "source": [
    "The classification reports reveal a catastrophic failure in our transfer learning model's ability to handle class distribution, with particularly devastating consequences for the minority \"both\" class.\n",
    "\n",
    "Transfer Learning Breakdown:\n",
    "\"both\" class complete failure: 0% precision and recall - the model never correctly identified any \"both\" images\n",
    "\n",
    "Severe bias toward Lacta: 85.4% recall for Lacta at the expense of all other classes\n",
    "\n",
    "Karamela neglect: Only 13.8% recall, indicating the model struggles with orange cat identification\n",
    "\n",
    "Macro F1-score collapse: 27.4% vs baseline's 54.7%, showing across-the-class performance degradation\n",
    "\n",
    "Baseline Model Strengths:\n",
    "Effective \"both\" detection: 76.9% recall demonstrates capability with the minority class\n",
    "\n",
    "Strong precision: 82.6% for Karamela and 94.1% for Lacta indicate confident, accurate predictions\n",
    "\n",
    "Balanced performance: Respectable metrics across all three classes despite imbalance\n",
    "\n",
    "Critical Insight:\n",
    "The transfer learning model developed a pathological bias - it essentially learned to predict \"Lacta\" for everything, completely ignoring the \"both\" class and mostly ignoring \"Karamela.\" This suggests the fine-tuning process may have caused catastrophic forgetting of feature diversity, or the class weighting strategy backfired dramatically.\n",
    "\n",
    "The baseline's superior performance across all metrics, particularly for the challenging \"both\" class, indicates that simpler architectures can sometimes outperform complex transfer learning approaches when dealing with small, imbalanced datasets and require careful hyperparameter tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60ce99-f2ce-4fdc-a06f-699c2c9e8986",
   "metadata": {},
   "source": [
    "## 4.3.3 Strategic Decision Point\n",
    "\n",
    "The detailed error analysis reveals that our transfer learning implementation didn't merely underperform—it failed catastrophically on fundamental aspects of our classification task. The complete neglect of the \"both\" class and severe bias toward Lacta indicate deeper architectural or training strategy issues that must be addressed.\n",
    "\n",
    "Root Cause Assessment:\n",
    "Class Weighting Backfire: The aggressive 2.14× weight for \"both\" may have destabilized learning\n",
    "\n",
    "Fine-Tuning Over-specialization: Unfreezing layers may have caused catastrophic forgetting of diverse feature detection\n",
    "\n",
    "Learning Rate Mismatch: The fine-tuning rate (1e-5) may be too conservative for meaningful adaptation\n",
    "\n",
    "Dataset Size Limitations: 380 samples may be insufficient for effective transfer learning fine-tuning\n",
    "\n",
    "#### Strategic Alternatives:\n",
    "- **Option A: Hyperparamter Tuning**\n",
    "\n",
    "   - Reduce class weight intensities\n",
    "\n",
    "   - Adjust learning rates and unfreezing strategy\n",
    "\n",
    "   - Maintain EfficientNetB0 architecture with modified training\n",
    "\n",
    "Option B: Architectural Shift\n",
    "\n",
    "Switch to a different pre-trained model (MobileNetV2, ResNet50)\n",
    "\n",
    "Implement progressive unfreezing with layer-specific learning rates\n",
    "\n",
    "Add stronger regularization to prevent over-specialization\n",
    "\n",
    "Option C: Hybrid Approach\n",
    "\n",
    "Combine transfer learning with data augmentation enhancements\n",
    "\n",
    "Implement class-balanced sampling instead of weighting\n",
    "\n",
    "Use ensemble methods to leverage both baseline and transfer learning strengths\n",
    "\n",
    "The pathological bias toward Lacta suggests we need fundamental changes rather than incremental adjustments. The baseline's proven effectiveness provides a solid fallback position while we explore more sophisticated solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12797a8a-8c1b-4a08-9e4f-6d8f69d86b54",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter Tuning Strategy\n",
    "\n",
    "Rationale: Before abandoning the EfficientNetB0 architecture, we conduct systematic hyperparameter optimization to determine if the performance issues stem from parameter selection rather than fundamental architectural incompatibility.\n",
    "\n",
    "Targeted Hyperparameters:\n",
    "\n",
    "- Class weight balancing: Address the pathological bias toward Lacta\n",
    "\n",
    "- Learning rate scheduling: Optimize the feature extraction vs fine-tuning balance\n",
    "\n",
    "- Layer unfreezing strategy: Control the specialization vs preservation trade-off\n",
    "\n",
    "Expected Outcome: Isolate the specific parameter configurations that enable transfer learning to leverage its theoretical advantages while avoiding the catastrophic failures observed in our initial implementation.\n",
    "\n",
    "We adopt a systematic approach, modifying one hyperparameter at a time to isolate its impact and understand the individual effects before combining optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459bfe4-9ba5-44b4-bf86-b754983f5129",
   "metadata": {},
   "source": [
    "## 5.1 Hyperparameter Tuning Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4344e7f3-38a1-4b31-818d-8ffc10420ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_configs = [\n",
    "    {'both': 1.2, 'karamela': 1.0, 'lacta': 0.9},    # Mild rebalancing\n",
    "    {'both': 1.5, 'karamela': 1.0, 'lacta': 0.8},    # Moderate rebalancing\n",
    "    {'both': 1.0, 'karamela': 1.0, 'lacta': 1.0}     # No weighting (control)\n",
    "]\n",
    "\n",
    "lr_configs = [1e-4, 5e-5, 1e-5]\n",
    "\n",
    "unfreezing_configs = [100, 150, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f1d41-a86d-4d56-a8dd-181bb7d90f5c",
   "metadata": {},
   "source": [
    "## 5.2 Iterative Parameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bacb139-8c42-4937-a948-67b8228d59ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
