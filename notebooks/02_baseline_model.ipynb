{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42db6a3-d49f-41a4-9de0-8b04f3a8a0a7",
   "metadata": {},
   "source": [
    "# Cat Classification Model Development\n",
    "# 1. Project Overview\n",
    "This notebook implements and evaluates machine learning models for classifying images containing either Lacta, Karamela, or both cats. The project follows a systematic approach to model development, starting with a simple baseline and progressing to advanced techniques to address the specific challenges identified in our data exploration.\n",
    "\n",
    "## 1.1 Data Exploration Insights & Challenges\n",
    "Our comprehensive data analysis revealed several critical characteristics that directly inform our modeling strategy:\n",
    "\n",
    "**Key Challenges Identified**\n",
    "- Class Imbalance: Significant under-representation of the \"both\" class (15.6% vs 49.3% Lacta, 35.2% Karamela) requiring specialized handling\n",
    "\n",
    "- Color Biases: Systematic brightness and color temperature differences between classes that could lead to model shortcuts\n",
    "\n",
    "- Visual Complexity: Diverse poses, scales, and occlusions demanding robust feature learning capabilities\n",
    "\n",
    "- Background Variations: Differing environmental contexts that may create spurious correlations\n",
    "\n",
    "**Mitigation Strategies**\n",
    "- Output Architecture: A three-class softmax output layer designed to directly learn spatial relationships for detecting multiple cats.\n",
    "\n",
    "- Stratified Data Splits: Maintained proportional class representation (70/15/15) across all datasets to preserve distribution.\n",
    "\n",
    "- Consistent Evaluation Framework: The same data splits are used for all models to ensure fair and comparable evaluations.\n",
    "\n",
    "## 1.2 Modeling Approach\n",
    "This notebook documents our progressive model development:\n",
    "\n",
    "1. Baseline CNN: Establish a performance benchmark and validate our data pipeline. This model serves as a diagnostic tool to isolate data issues from model capacity limitations.\n",
    "\n",
    "2. Transfer Learning: Leverage pre-trained models (e.g., ResNet, EfficientNet) to address the complex feature learning challenges posed by varied poses and lighting.\n",
    "\n",
    "3. Advanced Techniques: Implement methods like class weighting and data augmentation specifically targeting the class imbalance and identified biases.\n",
    "\n",
    "The prepared dataset with 546 images (Train: 380, Val: 83, Test: 83) serves as the consistent foundation for all experiments, enabling direct comparison between approaches and clear measurement of improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35c8d6-15f9-4ffb-bf46-7df6163a6ae9",
   "metadata": {},
   "source": [
    "# 2. Prerequisites\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4fdd50-5bd4-4930-ab1b-2ed92079bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPORTS FINISHED ===\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import importlib\n",
    "import config_class\n",
    "importlib.reload(config_class)\n",
    "\n",
    "from model_evaluation import visualize_training_history, evaluate_model\n",
    "from config_class import ConfigClass\n",
    "\n",
    "print(\"=== IMPORTS FINISHED ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5adb479-8924-4c1a-a273-9684850891ef",
   "metadata": {},
   "source": [
    "## 2.2 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662697ef-418f-4a5f-8e75-dec2f85b3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed'\n",
    "MODEL_PATH = '../models'\n",
    "\n",
    "# Image Processing\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74ad1d-45e0-4326-bd89-9509cebc0bbe",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "\n",
    "## 3.1 Data Augmentation Configuration\n",
    "We implement distinct data processing pipelines for training versus evaluation.\n",
    "The training generator employs extensive data augmentation to combat overfitting and improve model robustness, which is particularly crucial for amplifying the underrepresented 'both' class. The chosen parameters reflect realistic photographic variations while avoiding extreme distortions that would create implausible cat images. Specifically, the brightness_range parameter helps mitigate the color temperature biases identified during data exploration.\n",
    "Meanwhile, the validation and test generators perform only pixel normalization to ensure unbiased evaluation metrics that reflect true model generalization. We maintain separate generators for validation and testing to ensure consistent preprocessing across all evaluation phases and prevent any data leakage between splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc15d38-686d-4ecf-a2bf-3eb4b33e384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates separate data generators for training, validation, and test sets.\n",
    "    Training data is heavily augmented, while validation/test data is only normalized.\n",
    "    \"\"\"\n",
    "    # Training generator with heavy augmentation for minority classes\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.3,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        shear_range=0.1,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, val_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d799d-bdd1-46f7-aa25-ec35bb25b01a",
   "metadata": {},
   "source": [
    "## 3.2. Creating Data Generators\n",
    "With our augmentation strategy defined, we instantiate the data generators for training, validation, and testing. These generators handle image resizing, batch processing, and real-time augmentation during model training. The training generator uses shuffling to present the data in a random order for each epoch, which improves learning and prevents the model from memorizing the order of images. Conversely, the validation and test generators disable shuffling to ensure deterministic results and a reliable, consistent evaluation across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c12dc2e-dfda-424c-a16c-7bc1214ed410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train Generator ---\n",
      "Found 380 images belonging to 3 classes.\n",
      "--- Validation Generator ---\n",
      "Found 83 images belonging to 3 classes.\n",
      "--- Test Generator ---\n",
      "Found 83 images belonging to 3 classes.\n",
      "\n",
      "Class mapping: {'both': 0, 'karamela': 1, 'lacta': 2}\n",
      "\n",
      "--- Dataset Statistics ---\n",
      "Training samples:    380\n",
      "Validation samples:   83\n",
      "Test samples:         83\n"
     ]
    }
   ],
   "source": [
    "train_datagen, val_datagen, test_datagen = create_data_generators()\n",
    "\n",
    "# Create data generators\n",
    "print(\"--- Train Generator ---\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    f'{DATA_PATH}/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True, # Shuffle for training to prevent order memorization\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"--- Validation Generator ---\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    f'{DATA_PATH}/val', \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # No shuffle for consistent evaluation\n",
    ")\n",
    "\n",
    "print(\"--- Test Generator ---\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    f'{DATA_PATH}/test',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # No shuffle for consistent evaluation\n",
    ")\n",
    "\n",
    "# Verifies all generators have the same classes\n",
    "assert train_generator.class_indices == val_generator.class_indices == test_generator.class_indices, \"Class indices mismatch between generators!\"\n",
    "\n",
    "# Gets class mapping from the training generator\n",
    "baseline_classes = train_generator.class_indices\n",
    "print(f\"\\nClass mapping: {baseline_classes}\")\n",
    "\n",
    "# Prints dataset statistics\n",
    "print(\"\\n--- Dataset Statistics ---\")\n",
    "print(f\"Training samples:   {train_generator.samples:4d}\")\n",
    "print(f\"Validation samples: {val_generator.samples:4d}\")\n",
    "print(f\"Test samples:       {test_generator.samples:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580f6bc-e0ee-4b9e-ad19-dfd9a7c88749",
   "metadata": {},
   "source": [
    "## 3.3 Class Weights\n",
    "\n",
    "To mitigate the class imbalance identified during exploration, we implement class weighting using scikit-learn's `compute_class_weight` function. This technique increases the loss penalty for misclassifying minority class examples, forcing the model to allocate more learning capacity to underrepresented categories.\n",
    "\n",
    "We employ the 'balanced' strategy, which calculates weights inversely proportional to class frequencies:\n",
    "\n",
    "class_weight = total_samples / (classes_count * class_frequency)\n",
    "\n",
    "This ensures the model doesn't converge to a trivial majority-class predictor and learns meaningful features for all three classes.\n",
    "\n",
    "We chose class weighting over oversampling because it doesn't increase training time or risk overfitting on synthetic examples, while still providing strong incentives for the model to learn minority class patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e472cf73-b46c-4f18-83ff-f3b45f79dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      " {0: np.float64(2.146892655367232), 1: np.float64(0.945273631840796), 2: np.float64(0.6773618538324421)}\n"
     ]
    }
   ],
   "source": [
    "temp_class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(temp_class_weights))\n",
    "\n",
    "print(\"Class weights:\\n\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53446696-00b9-467c-9485-4b827186a24e",
   "metadata": {},
   "source": [
    "### Class Weight Analysis\n",
    "\n",
    "The calculated class weights reflect our dataset's imbalance:\n",
    "\n",
    "- **'both' (class 0)**: 2.14× weighting - Strong compensatory emphasis for our most underrepresented class\n",
    "- **'karamela' (class 1)**: 0.95× weighting - Near-balanced representation  \n",
    "- **'lacta' (class 2)**: 0.68× weighting - Reduced emphasis on the majority class\n",
    "\n",
    "These multiplicative factors will scale the loss function during training, effectively rebalancing the learning signal. This ensures that misclassifying a 'both' example carries approximately 3.15× (2.14/0.68) greater penalty than misclassifying a 'lacta' example, encouraging the model to develop robust features for all classes despite their uneven distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79c4df-c193-40a2-9130-9b2c20b7dd9b",
   "metadata": {},
   "source": [
    "# 4. Baseline Model Development\n",
    "\n",
    "This section focuses on establishing a fundamental performance benchmark for our cat classification task through the implementation of a simple Convolutional Neural Network (CNN). The baseline model serves as a critical reference point that will guide all subsequent model improvements and architectural decisions.\n",
    "\n",
    "In this section, we will systematically:\n",
    "\n",
    "- Select an appropriate CNN architecture that balances simplicity with learning capacity\n",
    "\n",
    "- Implement modular model creation functions to ensure reproducibility and enable efficient experimentation\n",
    "\n",
    "- Define an initial configuration based on established practices and our specific dataset characteristics\n",
    "\n",
    "- Train and evaluate the baseline model to establish performance metrics that will inform our optimization strategy\n",
    "\n",
    "The baseline approach allows us to isolate fundamental challenges—particularly class imbalance and limited training data—from architectural complexity, providing clear direction for the advanced techniques we will apply in later stages of the project.\n",
    "\n",
    "## 4.1 Model Architecture and Training Configuration\n",
    "This section defines the core components for our baseline training experiments. We implement a function to create the CNN architecture based on a configuration dictionary, alongside a complementary function to generate the training callbacks. This modular approach ensures all key aspects of the experiment—from model structure to the training dynamics—are centrally configured and easily reproducible.\n",
    "\n",
    "### Core Architectural Pattern\n",
    "We select a sequential convolutional neural network with three convolutional blocks followed by a classification head. This proven architecture provides a strong foundation for image classification tasks while maintaining simplicity for our baseline.\n",
    "\n",
    "#### Fixed Architectural Components\n",
    "1. **Convolutional Backbone Structure**\n",
    "- Three Convolutional Blocks: Fixed depth that balances complexity and trainability on our dataset size\n",
    "\n",
    "- 3×3 Kernel Size: Standard receptive field that captures local patterns efficiently while minimizing parameters\n",
    "\n",
    "- ReLU Activation: Provides non-linearity with proven performance and avoids vanishing gradient issues\n",
    "\n",
    "- 'same' Padding: Preserves spatial dimensions through convolutional operations\n",
    "\n",
    "2. **Spatial Hierarchy Design**\n",
    "- MaxPooling Layers: Using 2×2 pooling after each convolutional block\n",
    "\n",
    "- Fixed Reduction Pattern: Each block reduces spatial dimensions by half while increasing feature depth\n",
    "\n",
    "3. **Classification Head Architecture**\n",
    "- Global Flattening: We use a Flatten layer rather than Global Average Pooling to preserve all spatial information for this baseline model, as our dataset is small and feature-rich.\n",
    "\n",
    "- Single Dense Layer: Maintains simplicity while providing non-linear feature combination. Provides sufficient capacity for our 3-class problem without introducing excessive parameters that could lead to overfitting on our dataset of ~380 training images.\n",
    "\n",
    "- Dropout Layer: Essential regularization technique for our small dataset\n",
    "\n",
    "- Softmax Output: Appropriate for multi-class classification across our 3 categories\n",
    "\n",
    "4. **Training Foundation**\n",
    "- Adam Optimizer: Established adaptive learning rate method with proven convergence\n",
    "\n",
    "- Categorical Crossentropy: Standard loss function for multi-class classification problems\n",
    "\n",
    "#### Why These Fixed Choices?\n",
    "These architectural decisions represent established best practices in CNN design:\n",
    "\n",
    "- 3×3 convolutions are the building blocks of modern CNNs (VGG principle)\n",
    "\n",
    "- Three blocks provide sufficient depth for feature hierarchy without overcomplicating our baseline\n",
    "\n",
    "- ReLU remains the most widely used and reliable activation function\n",
    "\n",
    "- Adam optimizer offers robust performance across diverse problems\n",
    "\n",
    "This structure ensures our baseline is comparable to standard implementations while leaving room for hyperparameter optimization\n",
    "\n",
    "The specific filter counts, layer sizes, learning rates, and regularization strengths will be defined as tunable hyperparameters in the next section.\n",
    "\n",
    "5. **Training Strategy & Callbacks**\n",
    "\n",
    "- Early Stopping: Monitors validation loss to prevent overfitting and optimize training time\n",
    "\n",
    "- Model Checkpointing: Automatically saves the best-performing model based on validation accuracy\n",
    "\n",
    "- Learning Rate Scheduling: Reduces learning rate when validation loss plateaus to facilitate finer convergence\n",
    "\n",
    "- Multi-metric Monitoring: Tracks loss, accuracy, precision, and recall for comprehensive evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fd50c-75df-4eb4-acbd-62d574cf2b51",
   "metadata": {},
   "source": [
    "## 4.2 Model Implementation\n",
    "We now implement the architectural decisions outlined in the previous section through three modular functions. This design ensures reproducibility and facilitates systematic experimentation by centralizing all model configuration.\n",
    "\n",
    "`create_baseline_model(config)`: Constructs the sequential CNN architecture using the filter sizes specified in the configuration. The three convolutional blocks with increasing filter counts are designed to capture a hierarchy of features from simple edges to complex patterns.\n",
    "\n",
    "`compile_baseline_model(model, config)`: Configures the model's training process by setting the optimizer with its learning rate, the loss function, and evaluation metrics. We track accuracy, precision, and recall to get a comprehensive view of model performance.\n",
    "\n",
    "`create_baseline_training_callbacks(config, i)`: Defines the training dynamics. EarlyStopping halts training when validation loss stops improving, ModelCheckpoint saves the best model, and ReduceLROnPlateau refines the learning rate for better convergence. The i parameter allows saving multiple experiment runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9df3c50-306b-40cd-be81-ea76942c8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(\n",
    "    config\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a simple CNN baseline model\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(\n",
    "            shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "        ),\n",
    "        \n",
    "         # First convolutional block - basic feature detection\n",
    "        layers.Conv2D(\n",
    "            filters=config.conv_filters[0], \n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "        ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "         # Second convolutional block - intermediate features\n",
    "        layers.Conv2D(\n",
    "            filters=config.conv_filters[1],\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "        ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # Third convolutional block - complex pattern recognition\n",
    "        layers.Conv2D(\n",
    "            filters=config.conv_filters[2],\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "        ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        # Classification head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense( units=config.dense_units, activation='relu'),\n",
    "        layers.Dropout(config.dropout_rate),\n",
    "        \n",
    "        # Output layer - 3 classes with softmax probability distribution\n",
    "        layers.Dense(units=3, activation='softmax') # lacta, karamela, both\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "def compile_baseline_model(model, config):\n",
    "    \"\"\"\n",
    "    Compile the baseline model with appropriate settings\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=config.learning_rate),\n",
    "        loss='categorical_crossentropy',  # Categorical since we have 3 classes\n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_baseline_training_callbacks(config, i):\n",
    "    \"\"\"Create standardized training callbacks for consistent experimentation\"\"\"\n",
    "    return [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config.early_stopping_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(MODEL_PATH, f'baseline_model_{i}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=config.reduce_lr_factor,\n",
    "            patience=config.reduce_lr_patience,\n",
    "            min_lr=config.reduce_lr_min,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cfa81b-1d34-4be4-9e84-6c975a06064d",
   "metadata": {},
   "source": [
    "## 4.3 Initial Basline Hyperparameter Configuration\n",
    "This subsection defines the initial hyperparameter values for our baseline model and explains the rationale behind each choice based on our specific problem characteristics.\n",
    "\n",
    "### TrainingConfig Class Design\n",
    "Our TrainingConfig dataclass serves as a centralized configuration manager with update functionality, enabling:\n",
    "\n",
    "- Reproducible experiments through versioned configurations\n",
    "\n",
    "- Systematic hyperparameter tuning via the update() method\n",
    "\n",
    "- Clean experimentation workflow with reset and copy capabilities\n",
    "\n",
    "- Organized parameter management separating tunable values from fixed architecture\n",
    "\n",
    "### Initial Hyperparameter Values & Rationale\n",
    "**Training Schedule**\n",
    "- learning_rate = 1e-4: Conservative starting point to ensure stable convergence given our small dataset and class imbalance\n",
    "\n",
    "- epochs = 25: Sufficient to observe learning trends while allowing early stopping to prevent overfitting\n",
    "\n",
    "**Model Capacity & Regularization**\n",
    "- conv_filters = [32, 64, 128]: Progressive filter increase following CNN best practices, starting with sufficient capacity for basic feature detection\n",
    "\n",
    "- dense_units = 64: Reduced from typical values to prevent overparameterization given our 3-class output and limited data\n",
    "\n",
    "- dropout_rate = 0.5: Standard regularization strength to mitigate overfitting risks from our small training set\n",
    "\n",
    "**Training Optimization Parameters**\n",
    "\n",
    "- early_stopping_patience = 5: Allows sufficient epochs for the model to overcome temporary plateaus while preventing overfitting\n",
    "\n",
    "- reduce_lr_patience = 3: Balances responsive learning rate adaptation with stable training periods\n",
    "\n",
    "- reduce_lr_factor = 0.2: Provides moderate learning rate reduction to escape local minima without losing learned features\n",
    "\n",
    "- reduce_lr_min = 1e-7: Sets a reasonable lower bound for learning rate decay to maintain the ability to make fine weight adjustments even in late training stages.\n",
    "\n",
    "**Problem-Specific Considerations**\n",
    "These values are intentionally conservative to address our key challenges:\n",
    "\n",
    "- Class imbalance (15% \"both\" class) necessitates careful learning dynamics\n",
    "\n",
    "- Small dataset size (546 images) requires strong regularization and modest model capacity\n",
    "\n",
    "- Fine-grained classification (similar cat appearances) demands stable, gradual learning\n",
    "\n",
    "This configuration provides a sensible starting point that we can systematically optimize in subsequent experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e6cd7c-8dd8-45d3-b13f-2427a862257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineConfig:\n",
      "  learning_rate: 0.0001\n",
      "  epochs: 25\n",
      "  conv_filters: [32, 64, 128]\n",
      "  dense_units: 64\n",
      "  dropout_rate: 0.5\n",
      "  early_stopping_patience: 5\n",
      "  reduce_lr_patience: 3\n",
      "  reduce_lr_factor: 0.2\n",
      "  reduce_lr_min: 1e-07\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class BaselineConfig(ConfigClass):\n",
    "    # Training\n",
    "    learning_rate: float = 1e-4\n",
    "    epochs: int = 25\n",
    "    \n",
    "    # Model Architecture\n",
    "    conv_filters: List[int] = field(default_factory=lambda: [32, 64, 128])\n",
    "    dense_units: int = 64\n",
    "    dropout_rate: float = 0.5\n",
    "\n",
    "    # Training Callback\n",
    "    early_stopping_patience: int = 5\n",
    "    reduce_lr_patience: int = 3\n",
    "    reduce_lr_factor: float = 0.2\n",
    "    reduce_lr_min: float = 1e-7\n",
    "\n",
    "baseline_config_base = BaselineConfig()\n",
    "print(baseline_config_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf38360-3aef-4c41-a72b-a23058b85f5a",
   "metadata": {},
   "source": [
    "## 4.4 Initial Baseline Model Training and Evaluation\n",
    "This section documents the execution of our first complete training experiment using the configured baseline model. We proceed through three critical phases: model instantiation, the training process with monitored callbacks, and finally, a comprehensive evaluation on unseen test data. The results established here will serve as our fundamental benchmark for all subsequent model improvements.\n",
    "\n",
    "### 4.4.1 Model Creation and Compilation\n",
    "We now instantiate our first baseline model using the configuration defined in Section 4.3. The process involves creating a model instance with our specified architecture, followed by compilation with the chosen optimizer, loss function, and metrics. This prepares the model for the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3ce494-8c39-45d2-83f8-3901ce60e121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL ARCHITECTURE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)            </span>┃<span style=\"font-weight: bold\"> Output Shape     </span>┃<span style=\"font-weight: bold\">   Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, │       <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│                         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│                         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│                         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,592</span> │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────┴──────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, │       \u001b[38;5;34m896\u001b[0m │\n",
       "│                         │ \u001b[38;5;34m32\u001b[0m)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, │         \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)          │ \u001b[38;5;34m32\u001b[0m)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, │    \u001b[38;5;34m18,496\u001b[0m │\n",
       "│                         │ \u001b[38;5;34m64\u001b[0m)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,   │         \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)              │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,   │    \u001b[38;5;34m73,856\u001b[0m │\n",
       "│                         │ \u001b[38;5;34m128\u001b[0m)             │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ max_pooling2d_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,   │         \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)             │           │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)   │         \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │ \u001b[38;5;34m6,422,592\u001b[0m │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────┼──────────────────┼───────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)        │       \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────┴──────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,516,035</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,516,035\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,516,035</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,516,035\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_config_0 = baseline_config_base.copy()\n",
    "\n",
    "baseline_model_0 = create_baseline_model(baseline_config_0)\n",
    "baseline_model_0 = compile_baseline_model(baseline_model_0, baseline_config_0)\n",
    "\n",
    "print(\"\\n=== MODEL ARCHITECTURE ===\")\n",
    "baseline_model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fbc28-8012-494e-9773-f7199688c4f1",
   "metadata": {},
   "source": [
    "### Architecture Analysis\n",
    "\n",
    "The model summary reveals several key characteristics of our baseline design:\n",
    "\n",
    "**Parameter Distribution & Capacity**\n",
    "\n",
    "- Total Parameters: 6,516,035 - This represents a substantial model capacity relative to our dataset size (~380 training images)\n",
    "\n",
    "- Parameter Concentration: 98.5% of parameters (6,422,592) reside in the first dense layer following flattening, highlighting the transition from convolutional feature extraction to classification\n",
    "\n",
    "- Convolutional Efficiency: The three convolutional blocks contain only 93,248 parameters (1.4% of total), demonstrating the parameter efficiency of convolutional operations\n",
    "\n",
    "**Spatial Hierarchy & Feature Learning**\n",
    "\n",
    "- Spatial Reduction: Input dimensions systematically reduce from 224×224 → 112×112 → 56×56 → 28×28 through max-pooling operations\n",
    "\n",
    "- Feature Expansion: Filter counts progressively double (32 → 64 → 128) as spatial resolution decreases, following the standard CNN pattern of trading resolution for feature complexity\n",
    "\n",
    "- Flattening Impact: The flatten operation creates a 100,352-element vector (28×28×128), representing the high-dimensional feature space before classification\n",
    "\n",
    "**Design Implications**\n",
    "The architecture presents a classic trade-off: substantial representational capacity that could capture complex features, but significant overparameterization risk given our limited training data. The high parameter count in the dense layer particularly emphasizes the importance of our dropout regularization (0.5) to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af19a6-8fac-404b-a631-5ec832d2a81d",
   "metadata": {},
   "source": [
    "### 3.4.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d40ad86-933e-4936-9da8-e2a77ba0b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STARTING BASELINE TRAINING ===\n",
      "Training configuration:\n",
      "- Epochs: 25\n",
      "- Batch size: 32\n",
      "- Learning rate: 0.0001\n",
      "- Early stopping patience: 5\n",
      "Epoch 1/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3579 - loss: 1.0916 - precision: 0.4328 - recall: 0.1430\n",
      "Epoch 1: val_accuracy improved from None to 0.49398, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 7s/step - accuracy: 0.4079 - loss: 1.0725 - precision: 0.4661 - recall: 0.1447 - val_accuracy: 0.4940 - val_loss: 1.0164 - val_precision: 0.3000 - val_recall: 0.0361 - learning_rate: 1.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4416 - loss: 1.0664 - precision: 0.4482 - recall: 0.0509\n",
      "Epoch 2: val_accuracy did not improve from 0.49398\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.4605 - loss: 1.0365 - precision: 0.5227 - recall: 0.0605 - val_accuracy: 0.4940 - val_loss: 1.0090 - val_precision: 0.5094 - val_recall: 0.3253 - learning_rate: 1.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4775 - loss: 1.0082 - precision: 0.4784 - recall: 0.2163\n",
      "Epoch 3: val_accuracy did not improve from 0.49398\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.4947 - loss: 0.9981 - precision: 0.5348 - recall: 0.2632 - val_accuracy: 0.4940 - val_loss: 1.0032 - val_precision: 0.5152 - val_recall: 0.4096 - learning_rate: 1.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5113 - loss: 0.9857 - precision: 0.5768 - recall: 0.2321\n",
      "Epoch 4: val_accuracy improved from 0.49398 to 0.51807, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.5158 - loss: 1.0056 - precision: 0.5354 - recall: 0.1789 - val_accuracy: 0.5181 - val_loss: 0.9837 - val_precision: 0.5714 - val_recall: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5108 - loss: 1.0039 - precision: 0.6187 - recall: 0.1142\n",
      "Epoch 5: val_accuracy did not improve from 0.51807\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.5079 - loss: 1.0005 - precision: 0.5526 - recall: 0.1105 - val_accuracy: 0.5060 - val_loss: 0.9697 - val_precision: 0.5690 - val_recall: 0.3976 - learning_rate: 1.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5339 - loss: 0.9837 - precision: 0.5968 - recall: 0.2828\n",
      "Epoch 6: val_accuracy improved from 0.51807 to 0.68675, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.5500 - loss: 0.9712 - precision: 0.6065 - recall: 0.2474 - val_accuracy: 0.6867 - val_loss: 0.9380 - val_precision: 0.8438 - val_recall: 0.3253 - learning_rate: 1.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4983 - loss: 0.9948 - precision: 0.5558 - recall: 0.3017\n",
      "Epoch 7: val_accuracy improved from 0.68675 to 0.75904, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.5000 - loss: 0.9690 - precision: 0.5871 - recall: 0.3105 - val_accuracy: 0.7590 - val_loss: 0.9081 - val_precision: 0.8378 - val_recall: 0.3735 - learning_rate: 1.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5796 - loss: 0.9795 - precision: 0.6332 - recall: 0.2466\n",
      "Epoch 8: val_accuracy did not improve from 0.75904\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.5789 - loss: 0.9522 - precision: 0.6779 - recall: 0.2658 - val_accuracy: 0.5663 - val_loss: 0.8928 - val_precision: 0.6964 - val_recall: 0.4699 - learning_rate: 1.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6077 - loss: 0.8873 - precision: 0.6667 - recall: 0.3910\n",
      "Epoch 9: val_accuracy did not improve from 0.75904\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6237 - loss: 0.8926 - precision: 0.6749 - recall: 0.4316 - val_accuracy: 0.6145 - val_loss: 0.8297 - val_precision: 0.7213 - val_recall: 0.5301 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5705 - loss: 0.8976 - precision: 0.6810 - recall: 0.4035\n",
      "Epoch 10: val_accuracy did not improve from 0.75904\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.5895 - loss: 0.8865 - precision: 0.6909 - recall: 0.4000 - val_accuracy: 0.7470 - val_loss: 0.7686 - val_precision: 0.7846 - val_recall: 0.6145 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6296 - loss: 0.8916 - precision: 0.6522 - recall: 0.4388\n",
      "Epoch 11: val_accuracy improved from 0.75904 to 0.77108, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.6053 - loss: 0.9094 - precision: 0.6378 - recall: 0.4263 - val_accuracy: 0.7711 - val_loss: 0.7634 - val_precision: 0.8983 - val_recall: 0.6386 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6252 - loss: 0.8646 - precision: 0.6848 - recall: 0.4103\n",
      "Epoch 12: val_accuracy did not improve from 0.77108\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6368 - loss: 0.8605 - precision: 0.7256 - recall: 0.4105 - val_accuracy: 0.6747 - val_loss: 0.7670 - val_precision: 0.7344 - val_recall: 0.5663 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6350 - loss: 0.8577 - precision: 0.6714 - recall: 0.5190\n",
      "Epoch 13: val_accuracy did not improve from 0.77108\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6500 - loss: 0.8624 - precision: 0.6855 - recall: 0.5105 - val_accuracy: 0.7590 - val_loss: 0.6888 - val_precision: 0.8788 - val_recall: 0.6988 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5398 - loss: 0.9019 - precision: 0.6240 - recall: 0.4031\n",
      "Epoch 14: val_accuracy did not improve from 0.77108\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.5947 - loss: 0.8824 - precision: 0.6849 - recall: 0.4289 - val_accuracy: 0.6145 - val_loss: 0.8095 - val_precision: 0.6935 - val_recall: 0.5181 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6405 - loss: 0.8529 - precision: 0.6636 - recall: 0.4863\n",
      "Epoch 15: val_accuracy did not improve from 0.77108\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6500 - loss: 0.8478 - precision: 0.6792 - recall: 0.5237 - val_accuracy: 0.6386 - val_loss: 0.7623 - val_precision: 0.7164 - val_recall: 0.5783 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6280 - loss: 0.8487 - precision: 0.6853 - recall: 0.4386\n",
      "Epoch 16: val_accuracy did not improve from 0.77108\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6658 - loss: 0.8136 - precision: 0.7352 - recall: 0.4895 - val_accuracy: 0.7590 - val_loss: 0.6769 - val_precision: 0.8615 - val_recall: 0.6747 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6256 - loss: 0.8670 - precision: 0.7129 - recall: 0.5180\n",
      "Epoch 17: val_accuracy improved from 0.77108 to 0.78313, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6421 - loss: 0.8382 - precision: 0.7222 - recall: 0.5474 - val_accuracy: 0.7831 - val_loss: 0.6422 - val_precision: 0.8378 - val_recall: 0.7470 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6974 - loss: 0.7909 - precision: 0.7522 - recall: 0.5815\n",
      "Epoch 18: val_accuracy did not improve from 0.78313\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6684 - loss: 0.8014 - precision: 0.7482 - recall: 0.5474 - val_accuracy: 0.6988 - val_loss: 0.7305 - val_precision: 0.7313 - val_recall: 0.5904 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6225 - loss: 0.8311 - precision: 0.7199 - recall: 0.5049\n",
      "Epoch 19: val_accuracy did not improve from 0.78313\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6368 - loss: 0.8081 - precision: 0.7173 - recall: 0.5342 - val_accuracy: 0.7831 - val_loss: 0.6378 - val_precision: 0.8507 - val_recall: 0.6867 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6791 - loss: 0.7824 - precision: 0.7483 - recall: 0.5662\n",
      "Epoch 20: val_accuracy improved from 0.78313 to 0.79518, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6658 - loss: 0.7956 - precision: 0.7270 - recall: 0.5605 - val_accuracy: 0.7952 - val_loss: 0.6099 - val_precision: 0.8857 - val_recall: 0.7470 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6702 - loss: 0.7841 - precision: 0.7361 - recall: 0.5455\n",
      "Epoch 21: val_accuracy did not improve from 0.79518\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6526 - loss: 0.8043 - precision: 0.6942 - recall: 0.5079 - val_accuracy: 0.7349 - val_loss: 0.6860 - val_precision: 0.8361 - val_recall: 0.6145 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6886 - loss: 0.7720 - precision: 0.7335 - recall: 0.5294\n",
      "Epoch 22: val_accuracy did not improve from 0.79518\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6s/step - accuracy: 0.6816 - loss: 0.7986 - precision: 0.7279 - recall: 0.5421 - val_accuracy: 0.7349 - val_loss: 0.6911 - val_precision: 0.8644 - val_recall: 0.6145 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6521 - loss: 0.8282 - precision: 0.7085 - recall: 0.5174\n",
      "Epoch 23: val_accuracy improved from 0.79518 to 0.81928, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.6684 - loss: 0.8099 - precision: 0.7361 - recall: 0.5211 - val_accuracy: 0.8193 - val_loss: 0.6034 - val_precision: 0.8986 - val_recall: 0.7470 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6761 - loss: 0.7715 - precision: 0.7034 - recall: 0.5858\n",
      "Epoch 24: val_accuracy did not improve from 0.81928\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6s/step - accuracy: 0.6895 - loss: 0.7816 - precision: 0.7156 - recall: 0.6026 - val_accuracy: 0.7349 - val_loss: 0.6728 - val_precision: 0.7971 - val_recall: 0.6627 - learning_rate: 1.0000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6145 - loss: 0.8643 - precision: 0.6649 - recall: 0.5106\n",
      "Epoch 25: val_accuracy improved from 0.81928 to 0.83133, saving model to ../models\\baseline_model.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7s/step - accuracy: 0.6553 - loss: 0.8109 - precision: 0.6982 - recall: 0.5053 - val_accuracy: 0.8313 - val_loss: 0.6275 - val_precision: 0.9062 - val_recall: 0.6988 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "=== BASELINE TRAINING COMPLETED ===\n",
      "Training stopped at epoch 25\n",
      "Final validation accuracy: 0.8313\n"
     ]
    }
   ],
   "source": [
    "# Get standardized callbacks\n",
    "baseline_callbacks_0 = create_training_callbacks(baseline_config_0, 0)\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n=== STARTING BASELINE TRAINING ===\")\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"- Epochs: {baseline_config_0.epochs}\")\n",
    "print(f\"- Batch size: {baseline_config_0.batch_size}\")\n",
    "print(f\"- Learning rate: {baseline_config_0.learning_rate}\")\n",
    "print(f\"- Early stopping patience: {baseline_config_0.patience}\")\n",
    "\n",
    "baseline_history_0 = baseline_model_0.fit(\n",
    "    train_generator,\n",
    "    epochs=baseline_config_0.epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=baseline_callbacks_0,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=== BASELINE TRAINING COMPLETED ===\")\n",
    "print(f\"Training stopped at epoch {len(baseline_history_0.history['loss'])}\")\n",
    "print(f\"Final validation accuracy: {baseline_history_0.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32ff58-f6b8-499f-bd7b-86c0321ed9d5",
   "metadata": {},
   "source": [
    "Training Performance Assessment\n",
    "Positive Indicators\n",
    "Progressive Improvement: Validation accuracy steadily increased from 49.4% → 83.1% over 25 epochs\n",
    "\n",
    "Effective Learning: Model learned meaningful features, far exceeding random chance (33.3%)\n",
    "\n",
    "Stable Convergence: Training and validation metrics show consistent improvement patterns\n",
    "\n",
    "Best Model Selection: Early stopping correctly restored weights from epoch 23 with 81.9% validation accuracy\n",
    "\n",
    "Key Training Patterns\n",
    "Breakthrough at Epoch 6: Significant jump from 51.8% → 68.7% validation accuracy\n",
    "\n",
    "Progressive Refinement: Steady improvements from epoch 11-23 (77.1% → 81.9%)\n",
    "\n",
    "Final Surge: Strong finish at epoch 25 reaching 83.1% validation accuracy\n",
    "\n",
    "Metric Analysis\n",
    "High Precision (90.6%): Model is very reliable when it makes positive predictions\n",
    "\n",
    "Moderate Recall (69.9%): Suggests some missed detections, likely due to class imbalance\n",
    "\n",
    "Validation Consistency: Multiple epochs with similar performance indicates stable learning\n",
    "\n",
    "Architecture Validation\n",
    "The simple CNN architecture proved effective for this task, achieving strong baseline performance that provides a solid foundation for future optimizations and transfer learning approaches.\n",
    "\n",
    "This successful baseline establishes that our fundamental approach is sound and ready for more comprehensive evaluation in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6d832c3-0739-4f45-ac6b-93e888ee372c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m--------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m visualize_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204bd24-1038-4dfa-b6a2-5ad009369915",
   "metadata": {},
   "source": [
    "### 3.4.3 Model Evaluation\n",
    "\n",
    "This section provides a comprehensive evaluation of our first baseline model's performance on the test set, with particular focus on understanding how the class imbalance affects predictions across our three cat categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53349f68-0a0e-4487-816c-ce1c5078c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING BEST MODEL FOR EVALUATION ===\n",
      "\n",
      "=== TEST SET EVALUATION ===\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.8554 - loss: 0.6364 - precision: 0.8986 - recall: 0.7470\n",
      "Test Loss: 0.6364\n",
      "Test Accuracy: 0.8554\n",
      "Test Precision: 0.8986\n",
      "Test Recall: 0.7470\n",
      "\n",
      "=== PER-CLASS METRICS ===\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        both     0.8000    0.3077    0.4444        13\n",
      "    karamela     0.9286    0.8966    0.9123        29\n",
      "       lacta     0.8200    1.0000    0.9011        41\n",
      "\n",
      "    accuracy                         0.8554        83\n",
      "   macro avg     0.8495    0.7347    0.7526        83\n",
      "weighted avg     0.8548    0.8554    0.8335        83\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== LOADING BEST MODEL FOR EVALUATION ===\")\n",
    "model_0 = tf.keras.models.load_model(os.path.join(MODEL_PATH, 'baseline_model_0.keras'))\n",
    "\n",
    "evaluate_model(model_0, test_generator, baseline_classes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a3353-bc5e-41ef-a58c-9171ee4bf56a",
   "metadata": {},
   "source": [
    "Overall Performance Assessment\n",
    "Our baseline CNN model achieves strong overall performance with 85.5% test accuracy, demonstrating that the fundamental architecture is well-suited for this cat classification task. However, the per-class metrics reveal significant challenges with class imbalance.\n",
    "\n",
    "Key Findings\n",
    "Strengths\n",
    "Excellent Accuracy: 85.5% overall accuracy significantly exceeds random chance (33.3%)\n",
    "\n",
    "High Precision: 89.9% precision indicates reliable positive predictions\n",
    "\n",
    "Strong Majority Class Performance: Near-perfect performance on the largest class:\n",
    "\n",
    "Lacta: 100% recall - never misses Lacta when she's present\n",
    "\n",
    "Karamela: 89.7% recall - very reliable detection\n",
    "\n",
    "Critical Weakness - Class Imbalance Impact\n",
    "The model struggles significantly with the underrepresented \"both\" class:\n",
    "\n",
    "Very Low Recall (30.8%): Misses ~70% of images containing both cats\n",
    "\n",
    "Moderate Precision (80.0%): When it predicts \"both\", it's usually correct\n",
    "\n",
    "Poor F1-score (44.4%): Overall weak performance on this class\n",
    "\n",
    "Performance Analysis\n",
    "Macro vs Weighted Averages:\n",
    "\n",
    "Macro F1 (75.3%): Treats all classes equally, showing imbalance penalty\n",
    "\n",
    "Weighted F1 (83.4%): Weighted by support, reflects overall performance\n",
    "\n",
    "Recall-Precision Trade-off: High precision (89.9%) but lower recall (74.7%) suggests conservative predictions\n",
    "\n",
    "Implications for Next Steps\n",
    "This evaluation clearly identifies our primary challenge: improving detection of the \"both\" class. The baseline model effectively learns to distinguish individual cats but fails to reliably recognize when both are present together, likely due to:\n",
    "\n",
    "Limited training examples for the \"both\" class (only 59 training images)\n",
    "\n",
    "Model bias toward majority classes\n",
    "\n",
    "Potential feature overlap between single-cat and both-cat scenarios\n",
    "\n",
    "This provides clear direction for model improvements - we need techniques specifically addressing class imbalance in the next phase of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691846a7-363f-44eb-a4bc-b76a0dc30f8c",
   "metadata": {},
   "source": [
    "The learning curves reveal a baseline model that achieved modest but meaningful performance. With final training accuracy of 46.6% and validation accuracy of 48.2%, the model demonstrates it can learn to distinguish between our cats better than random chance (33.3%), though substantial improvement potential remains.\n",
    "\n",
    "The close alignment between training and validation metrics (48.2% vs 46.6% accuracy, 0.993 vs 1.027 loss) indicates good generalization without significant overfitting—a positive sign given our limited dataset. The consistent downward trend in both training and validation loss suggests the model was still learning when training concluded, potentially benefiting from additional epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52436f01-b610-4b58-a900-fa7463d08bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
